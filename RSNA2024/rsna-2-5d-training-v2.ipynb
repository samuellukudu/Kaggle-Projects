{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":9527735,"sourceType":"datasetVersion","datasetId":5609830}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Version 2 of 2.5 D model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# !pip install -q tensorflow-io","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:32.209062Z","iopub.execute_input":"2024-10-04T23:52:32.209458Z","iopub.status.idle":"2024-10-04T23:52:32.240904Z","shell.execute_reply.started":"2024-10-04T23:52:32.209420Z","shell.execute_reply":"2024-10-04T23:52:32.239483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, gc, sys, copy, pickle\n\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nimport glob\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom joblib import Parallel, delayed\nimport multiprocessing as mp\n\nimport albumentations as A\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.cuda.amp as amp\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import WeightedRandomSampler\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import model_selection\n\nfrom transformers import get_cosine_schedule_with_warmup, get_cosine_with_hard_restarts_schedule_with_warmup\n\nimport timm\n\nimport cv2\ncv2.setNumThreads(0)\nimport PIL\nimport pydicom\nfrom IPython import display\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2024-10-05T00:00:13.699280Z","iopub.execute_input":"2024-10-05T00:00:13.699838Z","iopub.status.idle":"2024-10-05T00:00:24.606236Z","shell.execute_reply.started":"2024-10-05T00:00:13.699772Z","shell.execute_reply":"2024-10-05T00:00:24.604883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    torch.manual_seed(SEED)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(SEED)\n        torch.cuda.manual_seed_all(SEED)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    print('seeding done!!!')\n\ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T00:00:24.609098Z","iopub.execute_input":"2024-10-05T00:00:24.609440Z","iopub.status.idle":"2024-10-05T00:00:24.617091Z","shell.execute_reply.started":"2024-10-05T00:00:24.609412Z","shell.execute_reply":"2024-10-05T00:00:24.615394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# timm.list_pretrained(\"densenet*\")\n# net = timm.create_model(\"resnet18d\", pretrained=True, num_classes=0)\n# x = torch.randn(2, 3, 224, 224)\n# net.forward_features(x).size()","metadata":{"execution":{"iopub.status.busy":"2024-10-05T00:00:24.618941Z","iopub.execute_input":"2024-10-05T00:00:24.619295Z","iopub.status.idle":"2024-10-05T00:00:24.653237Z","shell.execute_reply.started":"2024-10-05T00:00:24.619267Z","shell.execute_reply":"2024-10-05T00:00:24.651515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"CONFIG = dict(\n    load_kernel = None,\n    load_last = True,\n    n_folds = 5,\n    backbone = \"convnext_nano.in12k_ft_in1k\", # , tf_efficientnet_b0.ns_jft_in1k, convnext_pico.d1_in1k, convnext_nano.in12k_ft_in1k\n    img_size = 224,\n    n_slice_per_c = 10, # 10, 12, 16\n    axial_chans = 15,\n    axial_labels = 10,\n    axial_classes = 3 * 10,\n    \n    sagT1_chans = 15,\n    sagT1_labels = 10,\n    sagT1_classes = 3 * 10,\n    \n    sagT2_chans = 15,\n    sagT2_labels = 5,\n    sagT2_classes = 3 * 5,\n    \n    n_classes = 3 * 25,\n\n    drop_rate = 0.,\n    drop_rate_last = 0.3,\n    drop_path_rate = 0.,\n    p_mixup = 0.5,\n    p_rand_order_v1 = 0.2,\n    lr = 1e-4,\n\n    epochs = 40,\n    batch_size = 8,\n    warmup = 1,\n    num_cycles = 0.475,\n    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\",\n    seed = 42,\n    log_wandb = True,\n    with_clip = False,\n    use_lstm = True,\n)\n\nif CONFIG['log_wandb']:\n    name = CONFIG['backbone'].split('.')[0]\n    CONFIG['project_name'] = f\"RSNA2024-25Dv1-{name}\"\n    CONFIG['artifact_name'] = \"RSNA2024Model\"\n    import wandb\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n    wandb.login(key=secret_value_0)\n\nseeding(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-10-05T00:00:24.655371Z","iopub.execute_input":"2024-10-05T00:00:24.655753Z","iopub.status.idle":"2024-10-05T00:00:28.219702Z","shell.execute_reply.started":"2024-10-05T00:00:24.655722Z","shell.execute_reply":"2024-10-05T00:00:28.218018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load data","metadata":{}},{"cell_type":"code","source":"DATA_PATH = Path(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification\")\n\ntrain_main = pd.read_csv(DATA_PATH/\"train.csv\")\ntrain_desc = pd.read_csv(DATA_PATH/\"train_series_descriptions.csv\")\ntrain_labels = pd.read_csv(DATA_PATH/\"train_label_coordinates.csv\")\n\ntrain_main = train_main.fillna(-100)\n\nlabel2id = {'Normal/Mild': 0, 'Moderate':1, 'Severe':2}\ntrain_main = train_main.replace(label2id)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.063413Z","iopub.execute_input":"2024-10-04T23:52:41.063782Z","iopub.status.idle":"2024-10-04T23:52:41.298549Z","shell.execute_reply.started":"2024-10-04T23:52:41.063754Z","shell.execute_reply":"2024-10-04T23:52:41.297289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET_COLS = train_main.columns.tolist()[1:]\nAXIAL_COLS = {col:i for i, col in enumerate(train_main.columns[1:]) if 'subarticular_stenosis' in col}\nSAGT1_COLS = {col:i for i, col in enumerate(train_main.columns[1:]) if 'neural_foraminal_narrowing' in col}\nSAGT2_COLS = {col:i for i, col in enumerate(train_main.columns[1:]) if 'spinal_canal_stenosis' in col}\n\nCONDITIONS = [\n    'Spinal Canal Stenosis', \n    'Left Neural Foraminal Narrowing', \n    'Right Neural Foraminal Narrowing',\n    'Left Subarticular Stenosis',\n    'Right Subarticular Stenosis'\n]\n\nLEVELS = [\n    'L1/L2',\n    'L2/L3',\n    'L3/L4',\n    'L4/L5',\n    'L5/S1',\n]","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.300107Z","iopub.execute_input":"2024-10-04T23:52:41.300551Z","iopub.status.idle":"2024-10-04T23:52:41.309456Z","shell.execute_reply.started":"2024-10-04T23:52:41.300514Z","shell.execute_reply":"2024-10-04T23:52:41.308130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/rsna2024-data-split/rsna_folds.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.311355Z","iopub.execute_input":"2024-10-04T23:52:41.311818Z","iopub.status.idle":"2024-10-04T23:52:41.348433Z","shell.execute_reply.started":"2024-10-04T23:52:41.311777Z","shell.execute_reply":"2024-10-04T23:52:41.347297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.dcmread(path)\n    data = dicom.pixel_array\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = data - np.min(data)\n        \n    if np.max(data) != 0:\n        data = data / (np.max(data) + 1e-4)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef get_windowed_image(path, WC=100, WW=500):\n    # WC - WindowCenter, WW - WindowWidth\n    upper, lower = WC + WW//2, WC - WW//2\n    dcm = pydicom.dcmread(path)\n    pixel_array = dcm.pixel_array\n    \n    img = np.clip(pixel_array.copy(), lower, upper)\n    img = img - np.min(img)\n    img = img / np.max(img)\n    img = (img * 255.0).astype(np.uint8)\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.349908Z","iopub.execute_input":"2024-10-04T23:52:41.350259Z","iopub.status.idle":"2024-10-04T23:52:41.360058Z","shell.execute_reply.started":"2024-10-04T23:52:41.350230Z","shell.execute_reply":"2024-10-04T23:52:41.358799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class Spine25DDataset(Dataset):\n    def __init__(self, data, desc, mode='train', transform=None):\n        self.data = data\n        self.desc = desc\n        self.mode = mode\n        self.transform = transform\n        \n    \n    def __len__(self):\n        return len(self.data)\n    \n    def get_img_paths(self, study_id, series_desc):\n        pdf = self.desc[self.desc['study_id'] == study_id]\n        pdf_ = pdf[pdf['series_description'] == series_desc]\n        allimgs = []\n        for i, row in pdf_.iterrows():\n            pimgs = glob.glob(f\"{str(DATA_PATH)}/train_images/{study_id}/{row['series_id']}/*.dcm\")\n            pimgs = sorted(pimgs, key=lambda p: int(os.path.basename(p).split('.')[0]))\n            allimgs.extend(pimgs)\n        return allimgs\n    \n    def read_dcm(self, src_path):\n        img = load_dicom(src_path)\n        return img\n    \n    def get_images(self, nslides, image_paths):\n        H, W = CONFIG['img_size'], CONFIG['img_size']\n        IMAGES = np.zeros((nslides, H, W, 3), dtype=np.uint8)\n        for i in range(nslides):\n            try:\n                img = self.read_dcm(image_paths[i])\n                img = cv2.resize(img, (H,W)).astype(np.uint8)\n#                 img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n                img = img[..., None].repeat(3, -1)\n                img = self.transform(image=img)['image']\n                IMAGES[i, ...] = img\n            except:\n                pass\n            \n        return IMAGES\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        study_id = row.study_id\n        \n        axial_label = self.data.loc[idx, AXIAL_COLS.keys()].values.astype(int)\n        coronal_label = self.data.loc[idx, SAGT1_COLS.keys()].values.astype(int)\n        sagittal_label = self.data.loc[idx, SAGT2_COLS.keys()].values.astype(int)\n        \n        H, W = CONFIG['img_size'], CONFIG['img_size']\n        n_slides_per_c = CONFIG[\"n_slice_per_c\"]\n        sagittal = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        coronal = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        axial = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        \n        # Sagittal\n        allimgs_sag = self.get_img_paths(study_id, 'Sagittal T2/STIR')\n        \n        if len(allimgs_sag)==0:\n            pass\n        \n        else:\n            sagT2_scans = len(allimgs_sag)\n            sagT2_indices = np.quantile(list(range(sagT2_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_sag = [allimgs_sag[i] for i in sagT2_indices]\n            sagittal = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_sag)\n                \n        # coronal\n        allimgs_cor = self.get_img_paths(study_id, 'Sagittal T1')\n    \n        if len(allimgs_cor)==0:\n            pass\n        \n        else:\n            sagT1_scans = len(allimgs_cor)\n            sagT1_indices = np.quantile(list(range(sagT1_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_cor = [allimgs_cor[i] for i in sagT1_indices]\n            coronal = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_cor)\n                \n        # Axial\n        allimgs_ax = self.get_img_paths(study_id, 'Axial T2')\n        \n        if len(allimgs_ax)==0:\n            pass\n        \n        else:\n            ax_scans = len(allimgs_ax)\n            ax_indices = np.quantile(list(range(ax_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_ax = [allimgs_ax[i] for i in ax_indices]\n            axial = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_ax)\n        \n        axial = axial.transpose(0,3,1,2).astype(np.float32) / 255.0 \n        coronal = coronal.transpose(0,3,1,2).astype(np.float32) / 255.0 \n        sagittal = sagittal.transpose(0,3,1,2).astype(np.float32) / 255.0 \n        \n        if self.mode != 'test':\n            axial = torch.tensor(axial).float()\n            coronal = torch.tensor(coronal).float()\n            sagittal = torch.tensor(sagittal).float()\n            axial_label = torch.tensor([axial_label] * CONFIG[\"n_slice_per_c\"]).float()\n            coronal_label = torch.tensor([coronal_label] * CONFIG[\"n_slice_per_c\"]).float()\n            sagittal_label = torch.tensor([sagittal_label] * CONFIG[\"n_slice_per_c\"]).float()\n            \n            if self.mode == 'train' and random.random() < CONFIG['p_rand_order_v1']:\n                axial_indices = torch.randperm(axial.size(0))\n                coronal_indices = torch.randperm(coronal.size(0))\n                sagittal_indices = torch.randperm(sagittal.size(0))\n                axial = axial[axial_indices]\n                coronal = coronal[coronal_indices]\n                sagittal = sagittal[sagittal_indices]\n            return {\"axial\": axial, \"coronal\": coronal, \"sagittal\": sagittal, \n                    \"axial_target\": axial_label, \"coronal_target\": coronal_label, \"sagittal_target\": sagittal_label}\n        \n        else:\n            return {\"axial\": torch.tensor(axial).float(), \n                    \"coronal\": torch.tensor(coronal).float(), \n                    \"sagittal\": torch.tensor(sagittal).float()}","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.363688Z","iopub.execute_input":"2024-10-04T23:52:41.364077Z","iopub.status.idle":"2024-10-04T23:52:41.398349Z","shell.execute_reply.started":"2024-10-04T23:52:41.364046Z","shell.execute_reply":"2024-10-04T23:52:41.397029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Transformations and Dataloaders","metadata":{}},{"cell_type":"code","source":"def get_transforms(height, width):\n    train_tsfm = A.Compose([\n#         A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n        A.Resize(height=height, width=width),\n        A.Perspective(p=0.5),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n#         A.Rotate(limit=(-25, 25), p=0.5),\n        A.RandomBrightnessContrast(brightness_limit=0.7, p=0.7),\n        A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=30, border_mode=4, p=0.7),\n        \n        A.OneOf([\n            A.MotionBlur(blur_limit=3),\n            A.MedianBlur(blur_limit=3),\n            A.GaussianBlur(blur_limit=3),\n            A.GaussNoise(var_limit=(3.0, 9.0)),\n        ], p=0.5),\n        \n        A.OneOf([\n            A.OpticalDistortion(distort_limit=1.),\n            A.GridDistortion(num_steps=5, distort_limit=1.),\n            A.ElasticTransform(alpha=3),\n        ], p=0.5),\n        A.CoarseDropout(max_holes=1, max_height=int(height * 0.375), max_width=int(width * 0.375), p=0.5),\n    ])\n    \n    valid_tsfm = A.Compose([\n#         A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n        A.Resize(height=height, width=width),\n#         A.CenterCrop(height=height, width=width, p=1.0),\n    ])\n    return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\n\ndef get_dataloaders(data, desc, cfg, split=\"train\"):\n    img_size = cfg['img_size']\n    height, width = img_size, img_size\n    tsfm = get_transforms(height=height, width=width)\n    study_ids = data.study_id.unique().tolist()\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        ds = Spine25DDataset(data=data, desc=desc, mode='train', transform=tr_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=cfg['batch_size'], \n                         shuffle=True,\n                         num_workers=os.cpu_count(), \n                         drop_last=True, \n                         pin_memory=True, \n                         prefetch_factor=2)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        ds = Spine25DDataset(data=data, desc=desc, mode='valid', transform=eval_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=2*cfg['batch_size'], \n                         shuffle=False, \n                         num_workers=os.cpu_count(), \n                         drop_last=False, \n                         pin_memory=True, \n                         prefetch_factor=2)\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.399999Z","iopub.execute_input":"2024-10-04T23:52:41.400336Z","iopub.status.idle":"2024-10-04T23:52:41.419559Z","shell.execute_reply.started":"2024-10-04T23:52:41.400307Z","shell.execute_reply":"2024-10-04T23:52:41.418007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# dls = get_dataloaders(data=train_main, desc=train_desc, cfg=CONFIG, split='train')\n# b = next(iter(dls))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.420854Z","iopub.execute_input":"2024-10-04T23:52:41.421207Z","iopub.status.idle":"2024-10-04T23:52:41.432601Z","shell.execute_reply.started":"2024-10-04T23:52:41.421178Z","shell.execute_reply":"2024-10-04T23:52:41.431303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gc.collect()\n# k = 0\n# fig, axes = plt.subplots(2, 5, figsize=(12, 12))\n# axes = axes.flatten()\n# sag = b['sagittal'][k].detach().cpu().numpy().transpose(0,2,3,1)\n\n# for i in range(10):\n#     axes[i].imshow(sag[i, ...])\n#     axes[i].axis(False)\n# plt.tight_layout()\n# plt.show()\n# # b['axial'].shape\n# del sag","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.434015Z","iopub.execute_input":"2024-10-04T23:52:41.434487Z","iopub.status.idle":"2024-10-04T23:52:41.444550Z","shell.execute_reply.started":"2024-10-04T23:52:41.434458Z","shell.execute_reply":"2024-10-04T23:52:41.443344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class BaseModel(nn.Module):\n    def __init__(self, backbone, in_chans=3, pretrained=False, increase_stride=False):\n        super(BaseModel, self).__init__()\n\n        self.encoder = timm.create_model(\n            backbone,\n            in_chans=in_chans,\n            num_classes=0,\n            features_only=False,\n            drop_rate=CONFIG[\"drop_rate\"],\n            drop_path_rate=CONFIG[\"drop_path_rate\"],\n            pretrained=pretrained\n        )\n        self.encoder.name = backbone\n        self.nb_fts = self.encoder.num_features\n        self.gap = nn.AdaptiveAvgPool2d(1)\n#         self.gap = GeM(p_trainable=False)\n        \n        if increase_stride:\n            self.increase_stride()\n        \n    def increase_stride(self):\n        \"\"\"\n        Increase the stride of the first layer of the encoder\n        \"\"\"\n        if \"efficientnet\" in self.encoder.name:\n            self.encoder.conv_stem.stride = (4, 4)\n        elif \"nfnet\" in self.encoder.name:\n            self.encoder.stem.conv1.stride = (4, 4)\n        else:\n            raise NotImplementedError\n            \n    def forward(self, x):\n        x = self.encoder.forward_features(x)\n        x = self.gap(x)[:,:,0,0]\n        return x\n    \n    \nclass Clf(nn.Module):\n    def __init__(self, backbone, pretrained=False, increase_stride=False):\n        super(Clf, self).__init__()\n        self.axial_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                       pretrained=pretrained, increase_stride=increase_stride)\n        self.coronal_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                         pretrained=pretrained, increase_stride=increase_stride)\n        self.sagittal_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                          pretrained=pretrained, increase_stride=increase_stride)\n        \n        self.in_chans = 3\n        self.nb_fts = 3*self.axial_encoder.nb_fts\n        self.lstm = nn.LSTM(self.nb_fts, 256, num_layers=2, dropout=CONFIG[\"drop_rate\"], bidirectional=True, batch_first=True)\n        self.axial_head = self.get_head(CONFIG['axial_classes'])\n        self.coronal_head = self.get_head(CONFIG['sagT1_classes'])\n        self.sagittal_head = self.get_head(CONFIG['sagT2_classes'])\n    \n    \n    def get_head(self, n_classes):\n        head = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.Dropout(CONFIG[\"drop_rate_last\"]),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, n_classes),\n        )\n        return head\n    \n    def extract_features(self, x, view='axial'):\n        bs = x.shape[0]\n        x = x.view(bs * CONFIG[\"n_slice_per_c\"], self.in_chans, CONFIG[\"img_size\"], CONFIG[\"img_size\"])\n        if view == 'axial':\n            feat = self.axial_encoder(x)\n        elif view == 'coronal':\n            feat = self.coronal_encoder(x)\n        elif view == 'sagittal':\n            feat = self.sagittal_encoder(x)\n        else:\n            raise NotImplementedError\n            \n        feat = feat.view(bs, CONFIG[\"n_slice_per_c\"], -1)\n        return feat\n        \n        \n    def forward(self, ax, cor, sag):\n        bs = ax.shape[0]\n        ax_fts = self.extract_features(ax, view='axial')\n        cor_fts = self.extract_features(cor, view='coronal')\n        sag_fts = self.extract_features(sag, view='sagittal')\n        fts = torch.concatenate([ax_fts, cor_fts, sag_fts], dim=-1)\n        fts, _ = self.lstm(fts)\n        fts = fts.contiguous().view(bs * CONFIG[\"n_slice_per_c\"], -1)\n        ax_fts = self.axial_head(fts)\n        y_ax = ax_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"axial_classes\"]).contiguous()\n        cor_fts = self.coronal_head(fts)\n        y_cor = cor_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"sagT1_classes\"]).contiguous()\n        sag_fts = self.sagittal_head(fts)\n        y_sag = sag_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"sagT2_classes\"]).contiguous()\n        return y_ax, y_cor, y_sag","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.445913Z","iopub.execute_input":"2024-10-04T23:52:41.446268Z","iopub.status.idle":"2024-10-04T23:52:41.473743Z","shell.execute_reply.started":"2024-10-04T23:52:41.446241Z","shell.execute_reply":"2024-10-04T23:52:41.472493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter, defaultdict\n\nclass MetricMonitor:\n    def __init__(self, float_precision=4):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.476125Z","iopub.execute_input":"2024-10-04T23:52:41.476500Z","iopub.status.idle":"2024-10-04T23:52:41.489233Z","shell.execute_reply.started":"2024-10-04T23:52:41.476471Z","shell.execute_reply":"2024-10-04T23:52:41.487998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training arguments","metadata":{}},{"cell_type":"code","source":"gc.collect()\n\ndef get_loss(logits, labels, criterion):\n    loss = criterion(logits.view(-1, 3), labels.view(-1).to(torch.int64))\n    return loss\n\n# get_loss(o3, b['sagittal_target'], criterion)\ndef shared_step(model, batch, criterion):\n    axial = batch['axial'].to(CONFIG[\"device\"], non_blocking=True)\n    coronal = batch['coronal'].to(CONFIG[\"device\"], non_blocking=True)\n    sagittal = batch['sagittal'].to(CONFIG[\"device\"], non_blocking=True)\n    axial_target = batch['axial_target'].to(CONFIG[\"device\"], non_blocking=True)\n    coronal_target = batch['coronal_target'].to(CONFIG[\"device\"], non_blocking=True)\n    sagittal_target = batch['sagittal_target'].to(CONFIG[\"device\"], non_blocking=True)\n    \n    axial_logits, coronal_logits, sagittal_logits = model(axial, coronal, sagittal)\n    axial_loss = get_loss(axial_logits, axial_target, criterion=criterion)\n    coronal_loss = get_loss(coronal_logits, coronal_target, criterion)\n    sagittal_loss = get_loss(sagittal_logits, sagittal_target, criterion)\n    loss = axial_loss + coronal_loss + sagittal_loss\n    return {\n        \"loss\": loss / 3\n    }\n\n# shared_step(net, b, criterion)\ndef train(train_loader, model, criterion, optimizer, epoch, scaler, scheduler=None):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    train_loss = 0\n    for i, batch in enumerate(stream, start=1):\n        optimizer.zero_grad(set_to_none=True)\n        \n        with torch.autocast(device_type='cuda', dtype=torch.float16):\n            outputs = shared_step(model, batch, criterion)\n            loss =  outputs['loss']\n        \n        metric_monitor.update(\"Loss\", loss)\n        train_loss += loss.detach().float()\n        CONFIG['example_ct'] += len(batch[\"axial\"])\n        scaler.scale(loss).backward()\n        \n        # clip the gradient\n        if CONFIG['with_clip']:\n            scaler.unscale_(optimizer)\n            nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n        \n        lr = optimizer.param_groups[0]['lr']\n        scaler.step(optimizer)\n        scaler.update()\n        \n        _train_metrics = {\n            \"train/step_loss\": loss,\n            \"train/epoch\": (i + 1 + CONFIG['n_steps_per_epoch'] * CONFIG['epochs']),\n            \"train/example_ct\": CONFIG['example_ct'],\n            \"lr\": lr,\n        }\n        \n        if CONFIG['log_wandb'] and (i+1 < CONFIG['n_steps_per_epoch']):\n            wandb.log(_train_metrics)\n        \n        CONFIG['step_ct'] += 1\n        if scheduler is not None:\n            scheduler.step()\n        \n        stream.set_description(\n            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n        )\n        \n    total_train_loss = train_loss / len(train_loader)\n    _train_metrics['train/epoch_loss'] = total_train_loss\n    \n    flush()\n    return _train_metrics\n\n\ndef validate(val_loader, model, criterion, epoch):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    valid_loss = 0\n    \n    with torch.no_grad():\n        for i, batch in enumerate(stream, start=1):\n            with torch.autocast(device_type='cuda', dtype=torch.float16):\n                outputs = shared_step(model, batch, criterion)\n                loss =  outputs['loss']\n\n            metric_monitor.update(\"Loss\", loss)\n            valid_loss += loss.detach().float()\n            _valid_metrics = {\n                    \"valid/step_loss\": loss,\n                }\n            \n            stream.set_description(\n                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n            )\n            \n    total_valid_loss = valid_loss / len(val_loader)\n    _valid_metrics['valid/epoch_loss'] = total_valid_loss\n    flush()\n    return _valid_metrics","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.491222Z","iopub.execute_input":"2024-10-04T23:52:41.491592Z","iopub.status.idle":"2024-10-04T23:52:41.801753Z","shell.execute_reply.started":"2024-10-04T23:52:41.491558Z","shell.execute_reply":"2024-10-04T23:52:41.800401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_and_validate(model, train_dataset, val_dataset, desc, fold=0):\n    seeding(CONFIG['seed'])\n    \n    if CONFIG['log_wandb']:\n        run = wandb.init(\n            project=CONFIG[\"project_name\"],\n            resume=\"allow\",\n        )\n        artifact = wandb.Artifact(f\"{CONFIG['artifact_name']}_{fold}\", type=\"model\")\n    \n    if torch.cuda.is_available():\n        if torch.cuda.device_count() > 1:\n            DEVICE_IDS = list(range(torch.cuda.device_count()))\n            print(f\"\\nUsing {len(DEVICE_IDS)} GPUs to train ...\\n\")\n            model = nn.DataParallel(model, device_ids=DEVICE_IDS)\n            \n    model = model.to(CONFIG[\"device\"])\n#     model.apply(init_weights)\n    train_loader = get_dataloaders(data=train_dataset, desc=desc, cfg=CONFIG, split=\"train\")\n    valid_loader = get_dataloaders(data=val_dataset, desc=desc, cfg=CONFIG, split=\"valid\")\n    \n    n_steps_per_epoch = math.ceil(len(train_loader.dataset) / CONFIG['batch_size'])\n    CONFIG['n_steps_per_epoch'] = n_steps_per_epoch\n    CONFIG['example_ct'] = 0\n    CONFIG['step_ct'] = 0\n    \n    # weighted cross entropy loss\n    class_weights = torch.tensor([1, 2, 4], dtype=torch.float32)\n    criterion = nn.CrossEntropyLoss(weight=class_weights).to(CONFIG[\"device\"])\n \n    optimizer = torch.optim.AdamW(model.parameters(), lr=CONFIG[\"lr\"])\n    scaler = torch.cuda.amp.GradScaler()\n\n    scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=CONFIG[\"warmup\"] * CONFIG['n_steps_per_epoch'],\n            num_training_steps=CONFIG[\"epochs\"]* CONFIG['n_steps_per_epoch'],\n            num_cycles = CONFIG[\"num_cycles\"],\n        )\n    \n#     scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n#         optimizer,\n#         num_warmup_steps=CONFIG[\"warmup\"] * CONFIG['n_steps_per_epoch'],\n#         num_training_steps=CONFIG[\"epochs\"]* CONFIG['n_steps_per_epoch'],\n#         num_cycles = 2,\n#     )\n    \n    best_metric = np.inf\n    loss_min = np.inf\n    es = 0\n    ES_RATIO = 0.3 if CONFIG[\"epochs\"] <= 30 else 0.25\n    weights_file = \"rsna_2024_lumbar_spine_fold_{fold}_epoch_{epoch}.pth\"\n    for epoch in range(1, CONFIG[\"epochs\"] + 1):\n        _train_metrics = train(train_loader, model, criterion, optimizer, epoch, scaler, scheduler=scheduler)\n        _valid_metrics = validate(valid_loader, model, criterion, epoch)\n        \n        val_loss = _valid_metrics['valid/epoch_loss']\n        if CONFIG['log_wandb']:\n            wandb.log({**_train_metrics, **_valid_metrics})\n        \n        if val_loss < best_metric:\n            print(f\"Best metric: ({best_metric:.6f} --> {val_loss:.6f}). Saving model ...\")\n            if torch.cuda.device_count() > 2:\n                torch.save(model.module.state_dict(), weights_file.format(fold=fold, epoch=epoch))\n            else:\n                torch.save(model.state_dict(), weights_file.format(fold=fold, epoch=epoch))\n            best_metric = val_loss\n            if CONFIG['log_wandb']:\n                if epoch == 1:\n                    artifact.add_file(weights_file.format(fold=fold, epoch=epoch))\n                    run.log_artifact(artifact)\n                else:\n                    draft_artifact = wandb.Artifact(f\"{CONFIG['artifact_name']}_{fold}\", type=\"model\")\n                    draft_artifact.add_file(weights_file.format(fold=fold, epoch=epoch))\n                    run.log_artifact(draft_artifact)\n                \n            es = 0\n            \n        else:\n            es += 1\n            \n        if es > math.ceil(ES_RATIO*CONFIG[\"epochs\"]):\n            print(f\"Early stopping on epoch {epoch} ...\")\n            break\n    \n    if CONFIG['log_wandb']:\n        wandb.config = CONFIG\n        wandb.finish()\n        \n    del model, train_loader, valid_loader\n    flush()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.803689Z","iopub.execute_input":"2024-10-04T23:52:41.804350Z","iopub.status.idle":"2024-10-04T23:52:41.828642Z","shell.execute_reply.started":"2024-10-04T23:52:41.804318Z","shell.execute_reply":"2024-10-04T23:52:41.827135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold=0):\n    model = Clf(backbone=CONFIG['backbone'], pretrained=True, increase_stride=False)\n    train_ds = df[df['fold'] != fold].reset_index(drop=True)\n    valid_ds = df[df['fold'] == fold].reset_index(drop=True)\n    train_and_validate(model, train_ds, valid_ds, train_desc, fold=fold)\n    gc.collect()\n    flush()\n    \nrun(fold=0)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T23:52:41.830171Z","iopub.execute_input":"2024-10-04T23:52:41.831781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}