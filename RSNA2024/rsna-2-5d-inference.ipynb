{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"},{"sourceId":200032737,"sourceType":"kernelVersion"},{"sourceId":115173,"sourceType":"modelInstanceVersion","modelInstanceId":96731,"modelId":120919}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 2.5D Inference\n\nModel weights and cross validation [rsna-2-5dmodelcheckpoints-cross-validation](https://www.kaggle.com/code/samu2505/rsna-2-5dmodelcheckpoints-cross-validation) is here\n\nTraining notebook [rsna2024-training2-5dmodel](https://www.kaggle.com/code/samu2505/rsna2024-training2-5dmodel)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os, gc, sys, copy, pickle\nfrom pathlib import Path\nimport glob\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport math\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom joblib import Parallel, delayed\nimport multiprocessing as mp\n\nimport albumentations as A\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.cuda.amp as amp\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\nfrom torch.utils.data import WeightedRandomSampler\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn import model_selection\n\nfrom transformers import get_cosine_schedule_with_warmup\n\nimport timm\n\nimport cv2\ncv2.setNumThreads(0)\nimport PIL\nimport pydicom\nfrom IPython import display\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:01.353384Z","iopub.execute_input":"2024-10-08T12:53:01.353814Z","iopub.status.idle":"2024-10-08T12:53:09.169490Z","shell.execute_reply.started":"2024-10-08T12:53:01.353781Z","shell.execute_reply":"2024-10-08T12:53:09.168353Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    torch.manual_seed(SEED)\n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(SEED)\n        torch.cuda.manual_seed_all(SEED)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    print('seeding done!!!')\n\ndef flush():\n    gc.collect()\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:09.171296Z","iopub.execute_input":"2024-10-08T12:53:09.171662Z","iopub.status.idle":"2024-10-08T12:53:09.179267Z","shell.execute_reply.started":"2024-10-08T12:53:09.171627Z","shell.execute_reply":"2024-10-08T12:53:09.178098Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"CONFIG = dict(\n    project_name = \"RSNA-2024-25DModel\",\n    artifact_name = \"rsnaEffNetModel\",\n    load_kernel = None,\n    load_last = True,\n    n_folds = 5,\n    backbone = \"convnext_nano.in12k_ft_in1k\", # convnext_pico.d1_in1k, tf_efficientnet_b0.ns_jft_in1k\n    img_size = 224, # 224, 384\n    n_slice_per_c = 15,\n    in_chans = 3,\n    axial_chans = 10,\n    axial_labels = 10,\n    axial_classes = 3 * 10,\n    \n    sagT1_chans = 10,\n    sagT1_labels = 10,\n    sagT1_classes = 3 * 10,\n    \n    sagT2_chans = 10,\n    sagT2_labels = 5,\n    sagT2_classes = 3 * 5,\n    \n    n_classes = 3 * 25,\n\n    drop_rate = 0.,\n    drop_rate_last = 0.,\n    drop_path_rate = 0.,\n    p_mixup = 0.5,\n    p_rand_order_v1 = 0.2,\n    lr = 1e-3,\n    wd = 1e-4,\n\n    epochs = 5,\n    batch_size = 1,\n    warmup = 1,\n    num_cycles = 0.375,\n    device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\",\n    seed = 42,\n    log_wandb = False,\n    with_clip = False,\n    use_lstm = False,\n)\n\nif CONFIG['log_wandb']:\n    import wandb\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"WANDB_API_KEY\")\n    wandb.login(key=secret_value_0)\n\nseeding(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:09.180733Z","iopub.execute_input":"2024-10-08T12:53:09.181098Z","iopub.status.idle":"2024-10-08T12:53:09.198602Z","shell.execute_reply.started":"2024-10-08T12:53:09.181070Z","shell.execute_reply":"2024-10-08T12:53:09.197249Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"seeding done!!!\n","output_type":"stream"}]},{"cell_type":"code","source":"DATA_PATH = Path(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification\")\ntrain_main = pd.read_csv(DATA_PATH/\"train.csv\")\ntest_desc = pd.read_csv(DATA_PATH/\"test_series_descriptions.csv\")\nsample_df = pd.read_csv(DATA_PATH/\"sample_submission.csv\")\nstudy_ids = test_desc['study_id'].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:09.201006Z","iopub.execute_input":"2024-10-08T12:53:09.201688Z","iopub.status.idle":"2024-10-08T12:53:09.255489Z","shell.execute_reply.started":"2024-10-08T12:53:09.201656Z","shell.execute_reply":"2024-10-08T12:53:09.254353Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"AXIAL_COLS = {col:i for i, col in enumerate(train_main.columns[1:]) if 'subarticular_stenosis' in col}\nSAGT1_COLS = {col:i for i, col in enumerate(train_main.columns[1:]) if 'neural_foraminal_narrowing' in col}\nSAGT2_COLS = {col:i for i, col in enumerate(train_main.columns[1:]) if 'spinal_canal_stenosis' in col}","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:09.256689Z","iopub.execute_input":"2024-10-08T12:53:09.257024Z","iopub.status.idle":"2024-10-08T12:53:09.263516Z","shell.execute_reply.started":"2024-10-08T12:53:09.256995Z","shell.execute_reply":"2024-10-08T12:53:09.262237Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def load_dicom(path):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = data - np.min(data)\n        \n    if np.max(data) != 0:\n        data = data / (np.max(data) + 1e-4)\n    data = (data * 255).astype(np.uint8)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:09.264787Z","iopub.execute_input":"2024-10-08T12:53:09.265090Z","iopub.status.idle":"2024-10-08T12:53:09.273464Z","shell.execute_reply.started":"2024-10-08T12:53:09.265064Z","shell.execute_reply":"2024-10-08T12:53:09.272491Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Cropped dataset","metadata":{}},{"cell_type":"code","source":"seg_model = timm.create_model('resnet18', pretrained=False, num_classes=10)\n# path = \"/kaggle/input/k/samu2505/lumbar-coordinate-dataset-code/resnet18_2024.pt\"\npath = \"/kaggle/input/lumbar-coordinate-segmentation/pytorch/default/1/resnet18_2024.pt\"\nweights = torch.load(path, map_location=torch.device(\"cpu\"))\nseg_model.load_state_dict(weights)\nseg_model.to(CONFIG['device'])\nprint(\"seg model weights loaded succefully ...\")\n# seg_model.eval()\n\n@torch.no_grad()\ndef crop_single_image(net, image, cfg):\n    # Predict segmentation mask for the single image\n    size = image.shape[0]\n    tensor_image = torch.from_numpy(image).permute(2, 0, 1).float()\n    pred = net(torch.unsqueeze(tensor_image, dim=0).to(cfg['device'])).sigmoid().detach().cpu().numpy() * size\n    pred = pred.squeeze()\n    \n    # Extract x and y coordinates from the prediction\n    x_ = pred[0::2]\n    y_ = pred[1::2]\n    \n    # Calculate bounding box coordinates\n    xmin = np.min(x_).astype(int)\n    xmax = np.max(x_).astype(int)\n    ymin = np.min(y_).astype(int)\n    ymax = np.max(y_).astype(int)\n    \n    # Ensure bounding box is within image dimensions\n    xmin = max(0, xmin - 30)\n    xmax = min(size, xmax + 30)\n    ymin = max(0, ymin - 20)\n    ymax = min(size, ymax + 20)\n    \n    # Crop the image using the bounding box coordinates\n    cropped_img = image[ymin:ymax, xmin:xmax]\n    cropped_img = cv2.resize(cropped_img, (cfg['crop_width'], cfg['crop_height']))\n    return cropped_img\n\n\nclass CropDataset(Dataset):\n    def __init__(self, data, st_ids, cfg, model, mode='train', transform=None):\n        self.data = data\n        self.mode = mode\n        self.transform = transform\n        self.cfg = cfg\n        self.st_ids = st_ids\n        self.view = \"sagittal\"\n        self.seg_model = model\n    \n    def __len__(self):\n        return len(self.st_ids)\n    \n    def get_img_paths(self, study_id, series_desc):\n        pdf = self.data[self.data['study_id'] == study_id]\n        pdf_ = pdf[pdf['series_description'] == series_desc]\n        allimgs = []\n        for i, row in pdf_.iterrows():\n            pimgs = glob.glob(f\"{str(DATA_PATH)}/test_images/{study_id}/{row['series_id']}/*.dcm\")\n            pimgs = sorted(pimgs, key=lambda p: int(os.path.basename(p).split('.')[0]))\n            allimgs.extend(pimgs)\n        return allimgs\n    \n    def read_dcm(self, src_path):\n        img = load_dicom(src_path)\n        return img\n    \n    def get_images(self, nslides, image_paths):\n        H, W = self.cfg['img_size'], self.cfg['img_size']\n        IMAGES = np.zeros((nslides, H, W, 3), dtype=np.uint8)\n        for i in range(nslides):\n            try:\n                img = self.read_dcm(image_paths[i])\n                img = cv2.resize(img, (H,W)).astype(np.uint8)\n                img = img[..., None].repeat(3, -1)\n                if self.view == \"sagittal\":\n                    img = crop_single_image(self.seg_model, img, cfg=self.cfg)\n                img = self.transform(image=img)['image']\n                IMAGES[i, ...] = img\n            except:\n                pass\n            \n        return IMAGES\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        study_id = self.st_ids[idx]\n        \n        H, W = self.cfg['img_size'], self.cfg['img_size']\n        n_slides_per_c = self.cfg[\"n_slice_per_c\"]\n        sagittal = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        coronal = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        axial = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        \n        # Sagittal\n        allimgs_sag = self.get_img_paths(study_id, 'Sagittal T2/STIR')\n        \n        if len(allimgs_sag)==0:\n            pass\n        \n        else:\n            sagT2_scans = len(allimgs_sag)\n            sagT2_indices = np.quantile(list(range(sagT2_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_sag = [allimgs_sag[i] for i in sagT2_indices]\n            self.view = \"sagittal\"\n            sagittal = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_sag)\n                \n        # coronal\n        allimgs_cor = self.get_img_paths(study_id, 'Sagittal T1')\n    \n        if len(allimgs_cor)==0:\n            pass\n        \n        else:\n            sagT1_scans = len(allimgs_cor)\n            sagT1_indices = np.quantile(list(range(sagT1_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_cor = [allimgs_cor[i] for i in sagT1_indices]\n            self.view = \"sagittal\"\n            coronal = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_cor)\n                \n        # Axial\n        allimgs_ax = self.get_img_paths(study_id, 'Axial T2')\n        \n        if len(allimgs_ax)==0:\n            pass\n        \n        else:\n            ax_scans = len(allimgs_ax)\n            ax_indices = np.quantile(list(range(ax_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_ax = [allimgs_ax[i] for i in ax_indices]\n            self.view = \"axial\"\n            axial = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_ax)\n        \n        axial = axial.transpose(0, 3, 1, 2).astype(np.float32) / 255.0 \n        coronal = coronal.transpose(0, 3, 1, 2).astype(np.float32) / 255.0 \n        sagittal = sagittal.transpose(0, 3, 1, 2).astype(np.float32) / 255.0 \n        \n        return {\"axial\": axial, \"coronal\": coronal, \"sagittal\": sagittal, \"study_id\": str(study_id)}","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:09.274933Z","iopub.execute_input":"2024-10-08T12:53:09.275388Z","iopub.status.idle":"2024-10-08T12:53:10.240902Z","shell.execute_reply.started":"2024-10-08T12:53:09.275358Z","shell.execute_reply":"2024-10-08T12:53:10.239774Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"seg model weights loaded succefully ...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Full Dataset","metadata":{}},{"cell_type":"code","source":"class Spine25DDataset(Dataset):\n    def __init__(self, data, st_ids, transform=None):\n        self.data = data\n        self.st_ids = st_ids\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.st_ids)\n    \n    def get_img_paths(self, study_id, series_desc):\n        pdf = self.data[self.data['study_id'] == study_id]\n        pdf_ = pdf[pdf['series_description'] == series_desc]\n        allimgs = []\n        for i, row in pdf_.iterrows():\n            pimgs = glob.glob(f\"{str(DATA_PATH)}/test_images/{study_id}/{row['series_id']}/*.dcm\")\n            pimgs = sorted(pimgs, key=lambda p: int(os.path.basename(p).split('.')[0]))\n            allimgs.extend(pimgs)\n        return allimgs\n    \n    def read_dcm(self, src_path):\n        img = load_dicom(src_path)\n        return img\n    \n    def get_images(self, nslides, image_paths):\n        H, W = CONFIG['img_size'], CONFIG['img_size']\n        IMAGES = np.zeros((nslides, H, W, 3), dtype=np.uint8)\n        for i in range(nslides):\n            try:\n                img = self.read_dcm(image_paths[i])\n                img = cv2.resize(img, (H,W)).astype(np.uint8)\n#                 img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n                img = img[..., None].repeat(3, -1)\n                img = self.transform(image=img)['image']\n                IMAGES[i, ...] = img\n            except:\n                pass\n            \n        return IMAGES\n    \n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        study_id = self.st_ids[idx]\n        \n        H, W = CONFIG['img_size'], CONFIG['img_size']\n        n_slides_per_c = CONFIG[\"n_slice_per_c\"]\n        sagittal = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        coronal = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        axial = np.zeros((n_slides_per_c, H, W, 3), dtype=np.uint8)\n        \n        # Sagittal\n        allimgs_sag = self.get_img_paths(study_id, 'Sagittal T2/STIR')\n        if len(allimgs_sag)==0:\n            pass\n        \n        else:\n            sagT2_scans = len(allimgs_sag)\n            sagT2_indices = np.quantile(list(range(sagT2_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_sag = [allimgs_sag[i] for i in sagT2_indices]\n            sagittal = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_sag)\n                \n        # coronal\n        allimgs_cor = self.get_img_paths(study_id, 'Sagittal T1')\n        if len(allimgs_cor)==0:\n            pass\n        \n        else:\n            sagT1_scans = len(allimgs_cor)\n            sagT1_indices = np.quantile(list(range(sagT1_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_cor = [allimgs_cor[i] for i in sagT1_indices]\n            coronal = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_cor)\n                \n        # Axial\n        allimgs_ax = self.get_img_paths(study_id, 'Axial T2')\n        if len(allimgs_ax)==0:\n            pass\n        \n        else:\n            ax_scans = len(allimgs_ax)\n            ax_indices = np.quantile(list(range(ax_scans)), np.linspace(0., 1., n_slides_per_c)).round().astype(int)\n            allimgs_ax = [allimgs_ax[i] for i in ax_indices]\n            axial = self.get_images(nslides=n_slides_per_c, image_paths=allimgs_ax)\n        \n        axial = axial.transpose(0, 3, 1, 2).astype(np.float32) / 255.0 \n        coronal = coronal.transpose(0, 3, 1, 2).astype(np.float32) / 255.0 \n        sagittal = sagittal.transpose(0, 3, 1, 2).astype(np.float32) / 255.0 \n        \n        return {\"axial\": axial, \"coronal\": coronal, \"sagittal\": sagittal, \"study_id\": str(study_id)}","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.242352Z","iopub.execute_input":"2024-10-08T12:53:10.242670Z","iopub.status.idle":"2024-10-08T12:53:10.261389Z","shell.execute_reply.started":"2024-10-08T12:53:10.242643Z","shell.execute_reply":"2024-10-08T12:53:10.260357Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Dataloaders","metadata":{}},{"cell_type":"code","source":"def get_transforms(height, width):\n    train_tsfm = A.Compose([\n        A.Resize(height=height, width=height, interpolation=cv2.INTER_AREA),\n        A.Perspective(p=0.5),\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.Rotate(-25, 25, p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, border_mode=4, p=0.7),\n        \n        A.OneOf([\n            A.MotionBlur(blur_limit=3),\n            A.MedianBlur(blur_limit=3),\n            A.GaussianBlur(blur_limit=3),\n            A.GaussNoise(var_limit=(3.0, 9.0)),\n        ], p=0.5),\n        \n        A.OneOf([\n            A.OpticalDistortion(distort_limit=1.),\n            A.GridDistortion(num_steps=5, distort_limit=1.),\n        ], p=0.5),\n        \n        A.CoarseDropout(max_holes=2, max_height=int(height * 0.25), max_width=int(width * 0.25), p=0.3),\n    ])\n    \n    valid_tsfm = A.Compose([\n        A.Resize(height=height, width=width, interpolation=cv2.INTER_AREA),\n    ])\n    return {\"train\": train_tsfm, \"eval\": valid_tsfm}\n\ndef get_dataloaders(data, ids, cfg, split=\"test\"):\n    img_size = cfg['img_size']\n    height, width = img_size, img_size\n    tsfm = get_transforms(height=height, width=width)\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        ds = Spine25DDataset(data=data, st_ids=ids, transform=tr_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=cfg['batch_size'], \n                         shuffle=True,\n                         num_workers=os.cpu_count(), \n                         drop_last=True, \n                         pin_memory=True)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        ds = Spine25DDataset(data=data, st_ids=ids, transform=eval_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=cfg['batch_size'], \n                         shuffle=False, \n                         num_workers=os.cpu_count(), \n                         drop_last=False, \n                         pin_memory=True)\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls\n\n\ndef get_crop_dataloaders(data, ids, cfg, model, split=\"test\"):\n    img_size = cfg['img_size']\n    height, width = img_size, img_size\n    tsfm = get_transforms(height=height, width=width)\n    study_ids = data.study_id.unique().tolist()\n    if split == 'train':\n        tr_tsfm = tsfm['train']\n        ds = CropDataset(data=data, st_ids=ids, cfg=cfg, model=model, mode='train', transform=tr_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=cfg['batch_size'], \n                         shuffle=True,\n                         num_workers=os.cpu_count(), \n                         drop_last=True, \n                         pin_memory=True)\n        \n    elif split == 'valid' or split == 'test':\n        eval_tsfm = tsfm['eval']\n        ds = CropDataset(data=data, st_ids=ids, cfg=cfg, model=model, mode='valid', transform=eval_tsfm)\n        dls = DataLoader(ds, \n                         batch_size=2*cfg['batch_size'], \n                         shuffle=False, \n                         num_workers=os.cpu_count(),\n                         drop_last=False, \n                         pin_memory=True,\n                         persistent_workers=True,\n                        )\n    else:\n        raise Exception(\"Split should be 'train' or 'valid' or 'test'!!!\")\n    return dls","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.262988Z","iopub.execute_input":"2024-10-08T12:53:10.263356Z","iopub.status.idle":"2024-10-08T12:53:10.280578Z","shell.execute_reply.started":"2024-10-08T12:53:10.263320Z","shell.execute_reply":"2024-10-08T12:53:10.279546Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"code","source":"class BaseModel(nn.Module):\n    def __init__(self, backbone, in_chans=3, pretrained=False, increase_stride=False):\n        super(BaseModel, self).__init__()\n\n        self.encoder = timm.create_model(\n            backbone,\n            in_chans=in_chans,\n            num_classes=0,\n            features_only=False,\n            drop_rate=CONFIG[\"drop_rate\"],\n            drop_path_rate=CONFIG[\"drop_path_rate\"],\n            pretrained=pretrained\n        )\n        self.encoder.name = backbone\n        self.nb_fts = self.encoder.num_features\n        self.gap = nn.AdaptiveAvgPool2d(1)\n#         self.gap = GeM(p_trainable=False)\n        \n        if increase_stride:\n            self.increase_stride()\n        \n    def increase_stride(self):\n        \"\"\"\n        Increase the stride of the first layer of the encoder\n        \"\"\"\n        if \"efficientnet\" in self.encoder.name:\n            self.encoder.conv_stem.stride = (4, 4)\n        elif \"nfnet\" in self.encoder.name:\n            self.encoder.stem.conv1.stride = (4, 4)\n        else:\n            raise NotImplementedError\n            \n    def forward(self, x):\n        x = self.encoder.forward_features(x)\n        x = self.gap(x)[:,:,0,0]\n        return x\n    \nclass CroppedClf(nn.Module):\n    def __init__(self, backbone, pretrained=False, increase_stride=False):\n        super(CroppedClf, self).__init__()\n        self.axial_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                       pretrained=pretrained, increase_stride=increase_stride)\n        self.coronal_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                         pretrained=pretrained, increase_stride=increase_stride)\n        self.sagittal_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                          pretrained=pretrained, increase_stride=increase_stride)\n        \n        self.in_chans = 3\n        self.nb_fts = 3*self.axial_encoder.nb_fts\n        self.lstm = nn.LSTM(self.nb_fts, 256, num_layers=2, dropout=CONFIG[\"drop_rate\"], bidirectional=True, batch_first=True)\n        self.axial_head = self.get_head(CONFIG['axial_classes'])\n        self.coronal_head = self.get_head(CONFIG['sagT1_classes'])\n        self.sagittal_head = self.get_head(CONFIG['sagT2_classes'])\n    \n    \n    def get_head(self, n_classes):\n        head = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.Dropout(CONFIG[\"drop_rate_last\"]),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, n_classes),\n        )\n        return head\n    \n    def extract_features(self, x, view='axial'):\n        bs = x.shape[0]\n        x = x.view(bs * CONFIG[\"n_slice_per_c\"], self.in_chans, CONFIG[\"img_size\"], CONFIG[\"img_size\"])\n        if view == 'axial':\n            feat = self.axial_encoder(x)\n        elif view == 'coronal':\n            feat = self.coronal_encoder(x)\n        elif view == 'sagittal':\n            feat = self.sagittal_encoder(x)\n        else:\n            raise NotImplementedError\n            \n        feat = feat.view(bs, CONFIG[\"n_slice_per_c\"], -1)\n        return feat\n        \n        \n    def forward(self, ax, cor, sag):\n        bs = ax.shape[0]\n        ax_fts = self.extract_features(ax, view='axial')\n        cor_fts = self.extract_features(cor, view='coronal')\n        sag_fts = self.extract_features(sag, view='sagittal')\n        fts = torch.concatenate([ax_fts, cor_fts, sag_fts], dim=-1)\n        fts, _ = self.lstm(fts)\n        fts = fts.contiguous().view(bs * CONFIG[\"n_slice_per_c\"], -1)\n        ax_fts = self.axial_head(fts)\n        y_ax = ax_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"axial_classes\"]).contiguous()\n        cor_fts = self.coronal_head(fts)\n        y_cor = cor_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"sagT1_classes\"]).contiguous()\n        sag_fts = self.sagittal_head(fts)\n        y_sag = sag_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"sagT2_classes\"]).contiguous()\n        return y_ax, y_cor, y_sag\n    \n    \nclass Clf(nn.Module):\n    def __init__(self, backbone, pretrained=False, increase_stride=False):\n        super(Clf, self).__init__()\n        self.axial_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                       pretrained=pretrained, increase_stride=increase_stride)\n        self.coronal_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                         pretrained=pretrained, increase_stride=increase_stride)\n        self.sagittal_encoder = BaseModel(backbone=backbone, in_chans=3, \n                                          pretrained=pretrained, increase_stride=increase_stride)\n        \n        self.in_chans = 3\n        self.nb_fts = 3*self.axial_encoder.nb_fts\n        self.lstm = nn.LSTM(self.nb_fts, 256, num_layers=2, dropout=CONFIG[\"drop_rate\"], bidirectional=True, batch_first=True)\n        self.axial_head = self.get_head(CONFIG['axial_classes'])\n        self.coronal_head = self.get_head(CONFIG['sagT1_classes'])\n        self.sagittal_head = self.get_head(CONFIG['sagT2_classes'])\n    \n    \n    def get_head(self, n_classes):\n        head = nn.Sequential(\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.Dropout(CONFIG[\"drop_rate_last\"]),\n            nn.LeakyReLU(0.1),\n            nn.Linear(256, n_classes),\n        )\n        return head\n    \n    def extract_features(self, x, view='axial'):\n        bs = x.shape[0]\n        x = x.view(bs * CONFIG[\"n_slice_per_c\"], self.in_chans, CONFIG[\"img_size\"], CONFIG[\"img_size\"])\n        if view == 'axial':\n            feat = self.axial_encoder(x)\n        elif view == 'coronal':\n            feat = self.coronal_encoder(x)\n        elif view == 'sagittal':\n            feat = self.sagittal_encoder(x)\n        else:\n            raise NotImplementedError\n            \n        feat = feat.view(bs, CONFIG[\"n_slice_per_c\"], -1)\n        return feat\n        \n        \n    def forward(self, ax, cor, sag):\n        bs = ax.shape[0]\n        ax_fts = self.extract_features(ax, view='axial')\n        cor_fts = self.extract_features(cor, view='coronal')\n        sag_fts = self.extract_features(sag, view='sagittal')\n        fts = torch.concatenate([ax_fts, cor_fts, sag_fts], dim=-1)\n        fts, _ = self.lstm(fts)\n        fts = fts.contiguous().view(bs * CONFIG[\"n_slice_per_c\"], -1)\n        ax_fts = self.axial_head(fts)\n        y_ax = ax_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"axial_classes\"]).contiguous()\n        cor_fts = self.coronal_head(fts)\n        y_cor = cor_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"sagT1_classes\"]).contiguous()\n        sag_fts = self.sagittal_head(fts)\n        y_sag = sag_fts.view(bs, CONFIG[\"n_slice_per_c\"], CONFIG[\"sagT2_classes\"]).contiguous()\n        return y_ax, y_cor, y_sag","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.284211Z","iopub.execute_input":"2024-10-08T12:53:10.284746Z","iopub.status.idle":"2024-10-08T12:53:10.314511Z","shell.execute_reply.started":"2024-10-08T12:53:10.284717Z","shell.execute_reply":"2024-10-08T12:53:10.313226Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"CONDITIONS = [\n    'spinal_canal_stenosis', \n    'left_neural_foraminal_narrowing', \n    'right_neural_foraminal_narrowing',\n    'left_subarticular_stenosis',\n    'right_subarticular_stenosis'\n]\n\nLEVELS = [\n    'l1_l2',\n    'l2_l3',\n    'l3_l4',\n    'l4_l5',\n    'l5_s1',\n]\n\ndls = get_dataloaders(test_desc, study_ids, CONFIG, split='test')\ncropped_dls = get_crop_dataloaders(test_desc, study_ids, cfg=CONFIG, model=seg_model, split='test')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.316071Z","iopub.execute_input":"2024-10-08T12:53:10.316526Z","iopub.status.idle":"2024-10-08T12:53:10.332888Z","shell.execute_reply.started":"2024-10-08T12:53:10.316489Z","shell.execute_reply":"2024-10-08T12:53:10.331723Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def inference(model, dataloader):\n    model.to(CONFIG[\"device\"])\n    model.eval()\n    y_preds = []\n    row_names = []\n\n    axial_indices = list(AXIAL_COLS.values())\n    coronal_indices = list(SAGT1_COLS.values())\n    sagittal_indices = list(SAGT2_COLS.values())\n    \n    pbar = tqdm(dls, leave=True)\n    \n    with torch.no_grad():\n        for idx, batch in enumerate(pbar):\n            axial = batch['axial'].to(CONFIG[\"device\"], non_blocking=True)\n            coronal = batch['coronal'].to(CONFIG[\"device\"], non_blocking=True)\n            sagittal = batch['sagittal'].to(CONFIG[\"device\"], non_blocking=True)\n            si = batch['study_id']\n            pred_per_study = np.ones((25, 3)) * (1/3)\n            for cond in CONDITIONS:\n                for level in LEVELS:\n                    row_names.append(si[0] + '_' + cond + '_' + level)\n                \n            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n                y_axial, y_coronal, y_sagittal = model(axial, coronal, sagittal)\n                \n                y_axial_mean = y_axial.squeeze().mean(dim=0) \n                y_coronal_mean = y_coronal.squeeze().mean(dim=0) \n                y_sagittal_mean = y_sagittal.squeeze().mean(dim=0)\n                \n                y_axial_max = y_axial.squeeze().amax(dim=0) \n                y_coronal_max = y_coronal.squeeze().amax(dim=0) \n                y_sagittal_max = y_sagittal.squeeze().amax(dim=0)\n                \n                a = 0.5; b = 0.5\n                y_axial = a * y_axial_max + b * y_axial_mean\n                y_coronal = a * y_coronal_max + b * y_coronal_mean\n                y_sagittal = a * y_sagittal_max + b * y_sagittal_mean\n                \n                # axial\n                for col in range(CONFIG['axial_labels']):\n                    pred = y_axial[col*3:col*3+3]\n                    y_pred = pred.float().softmax(dim=-1).cpu().numpy()\n                    pred_per_study[axial_indices[col]] = y_pred\n                    \n                # coronal\n                for col in range(CONFIG['sagT1_labels']):\n                    pred = y_coronal[col*3:col*3+3]\n                    y_pred = pred.float().softmax(dim=-1).cpu().numpy()\n                    pred_per_study[coronal_indices[col]] = y_pred\n                    \n                # sagittal\n                for col in range(CONFIG['sagT2_labels']):\n                    pred = y_sagittal[col*3:col*3+3]\n                    y_pred = pred.float().softmax(dim=-1).cpu().numpy()\n                    pred_per_study[sagittal_indices[col]] = y_pred\n            y_preds.append(pred_per_study)\n            \n    y_preds = np.concatenate(y_preds, axis=0)\n    return y_preds, row_names","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.334257Z","iopub.execute_input":"2024-10-08T12:53:10.334608Z","iopub.status.idle":"2024-10-08T12:53:10.350622Z","shell.execute_reply.started":"2024-10-08T12:53:10.334580Z","shell.execute_reply":"2024-10-08T12:53:10.349514Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Load model weights","metadata":{}},{"cell_type":"code","source":"CKPTS = {\n    \"cropped_convnext_pico\": {\n        \"backbone\": \"convnext_pico.d1_in1k\",\n        \"path\": sorted([\n            f\"/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/cropped_convnext_pico_{i}.pth\" for i in [2, 3]\n        ]),\n    },\n    \"full_convnext_nano\": {\n        \"backbone\": \"convnext_nano.in12k_ft_in1k\",\n        \"path\": sorted([\n            f\"/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_{i}.pth\" for i in [0, 3, 4]\n        ])\n    },\n    \"full_convnext_pico\": {\n        \"backbone\": \"convnext_pico.d1_in1k\",\n        \"path\": sorted(glob.glob(\"/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_pico_*.pth\")),\n    },\n    \"full_efficientnet\": {\n        \"backbone\": \"tf_efficientnet_b0.ns_jft_in1k\",\n        \"path\": sorted(glob.glob(\"/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_*.pth\")),\n    },\n}\n\nCKPTS","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.352094Z","iopub.execute_input":"2024-10-08T12:53:10.352945Z","iopub.status.idle":"2024-10-08T12:53:10.379889Z","shell.execute_reply.started":"2024-10-08T12:53:10.352904Z","shell.execute_reply":"2024-10-08T12:53:10.378666Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"{'cropped_convnext_pico': {'backbone': 'convnext_pico.d1_in1k',\n  'path': ['/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/cropped_convnext_pico_2.pth',\n   '/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/cropped_convnext_pico_3.pth']},\n 'full_convnext_nano': {'backbone': 'convnext_nano.in12k_ft_in1k',\n  'path': ['/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_0.pth',\n   '/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_3.pth',\n   '/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_4.pth']},\n 'full_convnext_pico': {'backbone': 'convnext_pico.d1_in1k',\n  'path': ['/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_pico_0.pth']},\n 'full_efficientnet': {'backbone': 'tf_efficientnet_b0.ns_jft_in1k',\n  'path': ['/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_2.pth',\n   '/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_3.pth',\n   '/kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_4.pth']}}"},"metadata":{}}]},{"cell_type":"code","source":"CONVNEXT_MODELS = []\nEFFICIENT_MODELS = []\nCROPPED_MODELS = []\nfor model_name in CKPTS.keys():\n    backbone = CKPTS[model_name]['backbone']\n    weights_path = CKPTS[model_name]['path']\n    for path in weights_path:\n        if \"cropped\" in model_name:\n            model = CroppedClf(backbone=backbone)\n        else:\n            model = Clf(backbone=backbone)\n        weights = torch.load(path, map_location=torch.device(\"cpu\"))\n        model.load_state_dict(weights)\n        print(f\"\\n{model_name} weights {path} loaded successfully ...\")\n        if 'full_convnext' in model_name:\n            CONVNEXT_MODELS.append(model)\n        elif \"full_eff\" in model_name:\n            EFFICIENT_MODELS.append(model)\n        elif \"cropped_convnext\" in model_name:\n            CROPPED_MODELS.append(model)\n        else:\n            print(\"Not implemented\")\n            continue\n            \ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:10.381481Z","iopub.execute_input":"2024-10-08T12:53:10.381909Z","iopub.status.idle":"2024-10-08T12:53:28.679781Z","shell.execute_reply.started":"2024-10-08T12:53:10.381872Z","shell.execute_reply":"2024-10-08T12:53:28.678600Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\ncropped_convnext_pico weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/cropped_convnext_pico_2.pth loaded successfully ...\n\ncropped_convnext_pico weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/cropped_convnext_pico_3.pth loaded successfully ...\n\nfull_convnext_nano weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_0.pth loaded successfully ...\n\nfull_convnext_nano weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_3.pth loaded successfully ...\n\nfull_convnext_nano weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_nano_4.pth loaded successfully ...\n\nfull_convnext_pico weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_convnext_pico_0.pth loaded successfully ...\n\nfull_efficientnet weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_2.pth loaded successfully ...\n\nfull_efficientnet weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_3.pth loaded successfully ...\n\nfull_efficientnet weights /kaggle/input/rsna-2-5dmodelcheckpoints-cross-validation/full_tf_efficientnetb0_4.pth loaded successfully ...\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"45"},"metadata":{}}]},{"cell_type":"code","source":"convnext_outputs = [inference(net, dls) for net in CONVNEXT_MODELS]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:53:28.680933Z","iopub.execute_input":"2024-10-08T12:53:28.681292Z","iopub.status.idle":"2024-10-08T12:54:05.389704Z","shell.execute_reply.started":"2024-10-08T12:53:28.681264Z","shell.execute_reply":"2024-10-08T12:54:05.388064Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc94042c5ec47f3b9cf32b142686468"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6fef649f40a4218b6970d7d2bab9521"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e970cda90557448ab19b781954549acb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c14bfe126d2b4c8b8c9cb5c231c5be4a"}},"metadata":{}},{"name":"stderr","text":"Exception in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\nException ignored in: <function _ConnectionBase.__del__ at 0x785d5eaab2e0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"734"},"metadata":{}}]},{"cell_type":"code","source":"eff_outputs = [inference(net, dls) for net in EFFICIENT_MODELS]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:05.391977Z","iopub.execute_input":"2024-10-08T12:54:05.393013Z","iopub.status.idle":"2024-10-08T12:54:31.240078Z","shell.execute_reply.started":"2024-10-08T12:54:05.392968Z","shell.execute_reply":"2024-10-08T12:54:31.238643Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da2038b8e1a4f3e99e2ee17bbdc5ea9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aced9633920b462a86121b41588ef63f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"116cca33295440bb9e83f03368f2dd19"}},"metadata":{}},{"name":"stderr","text":"Exception in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nException in thread Exception in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nQueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException ignored in: <function _ConnectionBase.__del__ at 0x785d5eaab2e0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"546"},"metadata":{}},{"name":"stderr","text":"    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n","output_type":"stream"}]},{"cell_type":"code","source":"crop_convnext_outputs = [inference(net, cropped_dls) for net in CROPPED_MODELS]\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:31.242317Z","iopub.execute_input":"2024-10-08T12:54:31.243221Z","iopub.status.idle":"2024-10-08T12:54:48.238638Z","shell.execute_reply.started":"2024-10-08T12:54:31.243177Z","shell.execute_reply":"2024-10-08T12:54:48.237423Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b7d79bf95c5411699858cac2edc48f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e6dacbd15124451b2f3df36b9599704"}},"metadata":{}},{"name":"stderr","text":"Exception in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 239, in _feed\nException in thread QueueFeederThread:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 240, in _feed\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    reader_close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\n    # Message can fit in dest\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 177, in close\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nOSError: [Errno 9] Bad file descriptor\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n    self.run()\n  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n    self._target(*self._args, **self._kwargs)\n  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 271, in _feed\n    queue_sem.release()\nValueError: semaphore or lock released too many times\nException ignored in: <function _ConnectionBase.__del__ at 0x785d5eaab2e0>\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 132, in __del__\n    self._close()\n  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 361, in _close\n    _close(self._handle)\nOSError: [Errno 9] Bad file descriptor\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"376"},"metadata":{}}]},{"cell_type":"code","source":"# pred_convnext = convnext_outputs[0][0]\n# pred_efficient = eff_outputs[0][0]\n# pred_crop_convnext = crop_convnext_outputs[0][0]\nrow_ids = eff_outputs[0][1]\n\nconvnext_preds = np.array([convnext_outputs[i][0] for i in range(len(convnext_outputs))]).mean(axis=0)\neff_preds = np.array([eff_outputs[i][0] for i in range(len(eff_outputs))]).mean(axis=0)\ncrop_preds = np.array([crop_convnext_outputs[i][0] for i in range(len(crop_convnext_outputs))]).mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:48.240244Z","iopub.execute_input":"2024-10-08T12:54:48.240618Z","iopub.status.idle":"2024-10-08T12:54:48.249541Z","shell.execute_reply.started":"2024-10-08T12:54:48.240588Z","shell.execute_reply":"2024-10-08T12:54:48.248301Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"preds = 0.15*eff_preds + 0.15*crop_preds + 0.7*convnext_preds","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:48.251061Z","iopub.execute_input":"2024-10-08T12:54:48.251538Z","iopub.status.idle":"2024-10-08T12:54:48.262022Z","shell.execute_reply.started":"2024-10-08T12:54:48.251499Z","shell.execute_reply":"2024-10-08T12:54:48.260860Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"TARGET_COLS = sample_df.columns.tolist()\ndf = pd.DataFrame()\ndf['row_id'] = row_ids\ndf[['normal', 'mild', 'severe']] = preds\ndf.columns = TARGET_COLS\n# df = df.sort_values(\"row_id\").reset_index(drop=True)\ndf.to_csv('submission.csv', index=False, float_format='%.7f')","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:48.263421Z","iopub.execute_input":"2024-10-08T12:54:48.263783Z","iopub.status.idle":"2024-10-08T12:54:48.290233Z","shell.execute_reply.started":"2024-10-08T12:54:48.263755Z","shell.execute_reply":"2024-10-08T12:54:48.289018Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:48.293990Z","iopub.execute_input":"2024-10-08T12:54:48.294368Z","iopub.status.idle":"2024-10-08T12:54:48.317945Z","shell.execute_reply.started":"2024-10-08T12:54:48.294337Z","shell.execute_reply":"2024-10-08T12:54:48.316816Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                             row_id  normal_mild  moderate  \\\n0              44036939_spinal_canal_stenosis_l1_l2     0.223355  0.341723   \n1              44036939_spinal_canal_stenosis_l2_l3     0.148317  0.368259   \n2              44036939_spinal_canal_stenosis_l3_l4     0.148840  0.347878   \n3              44036939_spinal_canal_stenosis_l4_l5     0.257308  0.183269   \n4              44036939_spinal_canal_stenosis_l5_s1     0.746215  0.145340   \n5    44036939_left_neural_foraminal_narrowing_l1_l2     0.438979  0.536824   \n6    44036939_left_neural_foraminal_narrowing_l2_l3     0.230093  0.628808   \n7    44036939_left_neural_foraminal_narrowing_l3_l4     0.160885  0.477462   \n8    44036939_left_neural_foraminal_narrowing_l4_l5     0.081625  0.352821   \n9    44036939_left_neural_foraminal_narrowing_l5_s1     0.076223  0.281847   \n10  44036939_right_neural_foraminal_narrowing_l1_l2     0.379251  0.377329   \n11  44036939_right_neural_foraminal_narrowing_l2_l3     0.285019  0.588322   \n12  44036939_right_neural_foraminal_narrowing_l3_l4     0.141580  0.626190   \n13  44036939_right_neural_foraminal_narrowing_l4_l5     0.097698  0.311121   \n14  44036939_right_neural_foraminal_narrowing_l5_s1     0.088958  0.213563   \n15        44036939_left_subarticular_stenosis_l1_l2     0.183157  0.400919   \n16        44036939_left_subarticular_stenosis_l2_l3     0.083825  0.272608   \n17        44036939_left_subarticular_stenosis_l3_l4     0.058795  0.300811   \n18        44036939_left_subarticular_stenosis_l4_l5     0.050147  0.225457   \n19        44036939_left_subarticular_stenosis_l5_s1     0.178793  0.224761   \n20       44036939_right_subarticular_stenosis_l1_l2     0.182735  0.470293   \n21       44036939_right_subarticular_stenosis_l2_l3     0.107450  0.396191   \n22       44036939_right_subarticular_stenosis_l3_l4     0.067407  0.262865   \n23       44036939_right_subarticular_stenosis_l4_l5     0.063860  0.196513   \n24       44036939_right_subarticular_stenosis_l5_s1     0.151902  0.305108   \n\n      severe  \n0   0.434923  \n1   0.483424  \n2   0.503283  \n3   0.559423  \n4   0.108445  \n5   0.024198  \n6   0.141099  \n7   0.361653  \n8   0.565554  \n9   0.641930  \n10  0.243421  \n11  0.126659  \n12  0.232231  \n13  0.591180  \n14  0.697479  \n15  0.415924  \n16  0.643568  \n17  0.640394  \n18  0.724396  \n19  0.596446  \n20  0.346973  \n21  0.496359  \n22  0.669728  \n23  0.739626  \n24  0.542990  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>normal_mild</th>\n      <th>moderate</th>\n      <th>severe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n      <td>0.223355</td>\n      <td>0.341723</td>\n      <td>0.434923</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n      <td>0.148317</td>\n      <td>0.368259</td>\n      <td>0.483424</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n      <td>0.148840</td>\n      <td>0.347878</td>\n      <td>0.503283</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n      <td>0.257308</td>\n      <td>0.183269</td>\n      <td>0.559423</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n      <td>0.746215</td>\n      <td>0.145340</td>\n      <td>0.108445</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n      <td>0.438979</td>\n      <td>0.536824</td>\n      <td>0.024198</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n      <td>0.230093</td>\n      <td>0.628808</td>\n      <td>0.141099</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n      <td>0.160885</td>\n      <td>0.477462</td>\n      <td>0.361653</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n      <td>0.081625</td>\n      <td>0.352821</td>\n      <td>0.565554</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n      <td>0.076223</td>\n      <td>0.281847</td>\n      <td>0.641930</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n      <td>0.379251</td>\n      <td>0.377329</td>\n      <td>0.243421</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n      <td>0.285019</td>\n      <td>0.588322</td>\n      <td>0.126659</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n      <td>0.141580</td>\n      <td>0.626190</td>\n      <td>0.232231</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n      <td>0.097698</td>\n      <td>0.311121</td>\n      <td>0.591180</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n      <td>0.088958</td>\n      <td>0.213563</td>\n      <td>0.697479</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n      <td>0.183157</td>\n      <td>0.400919</td>\n      <td>0.415924</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n      <td>0.083825</td>\n      <td>0.272608</td>\n      <td>0.643568</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n      <td>0.058795</td>\n      <td>0.300811</td>\n      <td>0.640394</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n      <td>0.050147</td>\n      <td>0.225457</td>\n      <td>0.724396</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n      <td>0.178793</td>\n      <td>0.224761</td>\n      <td>0.596446</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n      <td>0.182735</td>\n      <td>0.470293</td>\n      <td>0.346973</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n      <td>0.107450</td>\n      <td>0.396191</td>\n      <td>0.496359</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n      <td>0.067407</td>\n      <td>0.262865</td>\n      <td>0.669728</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n      <td>0.063860</td>\n      <td>0.196513</td>\n      <td>0.739626</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n      <td>0.151902</td>\n      <td>0.305108</td>\n      <td>0.542990</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# # eff_outputs[0][0]\n# pd.DataFrame(preds, columns=['normal', 'mild', 'severe'])","metadata":{"execution":{"iopub.status.busy":"2024-10-08T12:54:48.319457Z","iopub.execute_input":"2024-10-08T12:54:48.319808Z","iopub.status.idle":"2024-10-08T12:54:48.324682Z","shell.execute_reply.started":"2024-10-08T12:54:48.319780Z","shell.execute_reply":"2024-10-08T12:54:48.323417Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}